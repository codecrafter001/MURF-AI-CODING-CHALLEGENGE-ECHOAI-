# ğŸ¤ AI Voice Agent

## âœ¨ Core Features
- One-tap voice chat (microphone â†’ AI answer with auto-played voice)  
- Multi-stage pipeline: STT â†’ LLM â†’ TTS  
- Persistent in-memory session history (per browser session id)  
- Real-time web search via Tavily (Gemini Function Calling)  
- WebSocket live transcripts + streamed TTS playback  
- Public demo safety: features are gated until users provide their own API keys (no shared secrets)  
- Sidebar Tools: Text to Speech generator (choose text â†’ Murf voice output), Echo Bot (record â†’ transcribe â†’ re-speak your words in another voice)  
- Keyboard shortcut: press **m** to toggle mic on/off  

## ğŸ§  Architecture Flow
- User presses **Start Speaking** â†’ Browser records audio (MediaRecorder)  
- Audio uploaded to `/agent/chat/{session_id}`  
- AssemblyAI transcribes bytes â†’ text  
- Chat history compiled into a Gemini prompt  
- Gemini generates assistant reply  
- Murf API converts reply text to speech (default voice: en-US-charles)  
- Frontend auto-plays the returned audio & renders chat bubbles  
- User Voice â†’ FastAPI â†’ AssemblyAI â†’ Gemini â†’ Murf â†’ Browser Playback  
- Supports **real-time streaming** via WebSocket (`/ws`) with partial transcripts and chunked TTS audio  

## ğŸ—‚ï¸ Project Structure
- **app/** â†’ Main application folder  
  - `main.py` â†’ FastAPI entrypoint (routes import service layer)  
  - **services/** â†’ Domain/service logic  
    - `stt_service.py` â†’ AssemblyAI transcription helpers  
    - `tts_service.py` â†’ Murf.ai TTS client wrapper  
    - `llm_service.py` â†’ Gemini client + prompt builder + function calling  
    - `weather_service.py`  
    - `murf_ws_service.py` â†’ Murf WebSocket streaming (chunked TTS)  
    - `web_search_service.py` â†’ Tavily search wrapper  
    - `streaming_transcriber.py` â†’ AssemblyAI streaming transcription  
  - **schemas/** â†’ Pydantic models (`tts.py`: TextToSpeechRequest, ChatResponse, etc.)  
  - **templates/** â†’ UI shell (`index.html`)  
  - **static/** â†’ Frontend assets (CSS, JS, images, sounds)  
  - **uploads/** â†’ Temp upload storage (optional)  
- `requirements.txt` â†’ Dependencies  
- `.env` â†’ Local API keys (not committed)  
- `.gitignore` â†’ Ignore rules  
- `README.md` â†’ Documentation  

## ğŸ”‘ Environment Variables
Add a `.env` file in the project root (optional fallback for dev):  
Create a .env file in the project root (optional; for local fallback):

ASSEMBLYAI_API_KEY=your_assemblyai_key
GEMINI_API_KEY=your_gemini_key
MURF_API_KEY=your_murf_key
TAVILY_API_KEY=your_tavily_key
OPENWEATHER_API_KEY=your_openweather_key
Notes:

For public deployments, users must enter their own keys via the inâ€‘app Settings modal. Server keys are optional fallback for private/dev.
Do not commit .env. Share .env.example with placeholders instead.
Where to get API keys
AssemblyAI: https://www.assemblyai.com/app/account
Gemini (Google AI Studio): https://aistudio.google.com/app/apikey
Murf AI: https://murf.ai/api (Account settings â†’ API key)
Tavily: https://app.tavily.com/ (Dashboard â†’ API Keys)
OpenWeather: https://home.openweathermap.org/api_keys
Tip: copy .env.example to .env and fill your values. Never commit .env.

##ğŸš€ Quick Start
# 1. Create & activate a virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows

# 2. Install dependencies
pip install -r requirements.txt

# 3. Add your .env file (see above)

# 4. Run the server (simple dev mode)
cd app && python main.py

# 5. Open in browser
http://127.0.0.1:8000/

# (Alt) Use uvicorn directly for auto-reload (optional)
# cd app && uvicorn main:app --reload

## ğŸ“¡ Key Endpoints

| Method | Endpoint                  | Purpose                                              |
|--------|---------------------------|------------------------------------------------------|
| POST   | `/agent/chat/{session_id}` | Voice chat: audio â†’ transcription â†’ LLM â†’ TTS        |
| POST   | `/tts/echo`                | Echo tool (repeat what you said with Murf)           |
| POST   | `/generate_audio`          | Direct text â†’ speech (Murf)                          |
| POST   | `/transcribe/file`         | Raw transcription (AssemblyAI)                       |
| WS     | `/ws`                      | Streaming: partial transcripts + chunked TTS         |
| GET    | `/debug/web_search`        | Tavily test: `?query=your+question`                  |
| GET    | `/debug/llm_chat`          | LLM (no audio): `?q=hello`                          |
| POST   | `/debug/llm_chat_text`     | LLM (no audio): `{ "text": "hello" }`               |

## ğŸ§ª Tech Highlights
- FastAPI backend with **service + schema layering** (clean separation)  
- AssemblyAI transcription (resilient + fallback path)  
- Google Gemini (`gemini-1.5-flash`) via reusable client & retry logic  
- Gemini Function Calling with a **web_search tool** backed by Tavily  
- Murf AI TTS wrapped in a lightweight client (consistent error handling)  
- Murf WebSocket streaming with safe chunking to speak full answers  
- MediaRecorder + multipart upload for low-latency voice capture  
- Autoplay + replay logic with audio unlock and retry  
- Structured **Pydantic responses** for clearer API contracts  
- Per-session key overrides wired from UI â†’ backend (no keys echoed back)  

## ğŸ”„ Session Handling
- Browser **session id** appended to URL (query param)  
- History stored in **in-memory dict (`CHAT_HISTORY`)**  
- Suitable for prototyping; swap with **Redis/DB** for production scaling  

## ğŸ›¡ï¸ Notes / Limits
- Public mode gates features until users provide keys (Settings auto-opens on first use)  
- Not production-hardened (**no auth, rate limiting, or persistence yet**)  
- API keys must remain secret (`.env` not committed)  
- In-memory history resets on server restart (swap with **Redis/DB** later)  
- Gemini key must be loaded before first request (**lazy reconfigure added**)  

## ğŸ¤ Contributing
- Prototype phase â€” open issues with ideas (latency, UI/UX, voice packs, multilingual support)  
- PRs welcome after discussion  

## ğŸ“„ License
- Licensed under **MIT License** (see LICENSE.txt)  

## ğŸ™Œ Acknowledgements
- **AssemblyAI** â†’ Speech-to-text  
- **Google Gemini** â†’ Language understanding  
- **Murf AI** â†’ High-quality synthetic voices  
- **FastAPI** â†’ Rapid backend framework  
- Built as part of **30-Day AI Voice Agent Challenge by Murf.ai**  

